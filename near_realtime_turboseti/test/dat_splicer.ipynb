{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-82701fcd96a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mFileIDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mFileIDs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#header_lines[:][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#This notebook is a prototype for a script that will splice individual\n",
    "#UFUDs into UFSD files. \n",
    "\n",
    "#Ellie White, 26 Jan 2021\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from astropy.io import ascii\n",
    "\n",
    "np.set_printoptions(threshold= sys.maxsize)\n",
    "\n",
    "#first, read in the .dat files for the first scan in the cadence:\n",
    "#Need to figure out how to make the filenames more general or at least \n",
    "#how to make them work for running on the GBO machine\n",
    "\n",
    "nodes_list = ['00', '01', '02', '03', '04', '05', '06', '11', \\\n",
    "              '12', '13', '14', '15', '16', '21', '22', '23', \\\n",
    "              '24', '25', '26', '27']\n",
    "\n",
    "filenames_list = []\n",
    "\n",
    "for node in nodes_list:\n",
    "    filename = '/datax/scratch/ewhite/voyager-xband/dat_files/BLC{0}/fine_res/'\\\n",
    "               'blc{0}_guppi_59046_80036_DIAG_VOYAGER-1_0011.rawspec.0000.dat'.format(node)\n",
    "    filenames_list.append(filename)\n",
    "\n",
    "for fname in filenames_list:\n",
    "    fname_idx = filenames_list.index(fname)\n",
    "    ufud = ascii.read(fname)\n",
    "    ufud = ufud.to_pandas()\n",
    "    #ufud = ufud.apply(pd.to_numeric)\n",
    "\n",
    "    if fname_idx == 0:\n",
    "        ufsd = ufud\n",
    "    else:\n",
    "        ufsd.append(ufud)\n",
    "        \n",
    "\n",
    "\n",
    "FileIDs = []\n",
    "\n",
    "for h in header_lines[:][1]:\n",
    "    print(h)\n",
    "    FileIDs.append(h.strip().split(':')[-1].strip()) #header_lines[:][0]\n",
    "\n",
    "print('Here are the File IDs')\n",
    "print(FileIDs)\n",
    "\n",
    "Source = header_lines[0][1]\n",
    "\n",
    "MJD = header_lines[0][2] #hits[4].strip().split('\\t')[0].split(':')[-1].strip()\n",
    "RA =  header_lines[0][3] #hits[4].strip().split('\\t')[1].split(':')[-1].strip()\n",
    "DEC = header_lines[0][4] #hits[4].strip().split('\\t')[2].split(':')[-1].strip()\n",
    "\n",
    "DELTAT = header_lines[0] #hits[5].strip().split('\\t')[0].split(':')[-1].strip()  # s\n",
    "DELTAF = header_lines[0] #hits[5].strip().split('\\t')[1].split(':')[-1].strip()  # Hz\n",
    "\n",
    "#dat_info = np.array(dat_info, float)\n",
    "\n",
    "'''#sort the rows so they are in order of frequency, descending\n",
    "freq_index = 4\n",
    "sorted_dat_info = dat_info[dat_info[:,freq_index].argsort()[::-1]]\n",
    "\n",
    "#replace Total_Hit_# values so they are unique for each\n",
    "#row and are natural numbers, matching the turboSETI convention\n",
    "total_hit_nums = np.arange(1, num_rows+1, 1)\n",
    "sorted_dat_info[:,0] = total_hit_nums\n",
    "\n",
    "#address coarse channel numbers\n",
    "sorted_coarse_chans = []\n",
    "chan_num = 0\n",
    "\n",
    "for c in range(num_rows):\n",
    "    if c == 0:\n",
    "        sorted_coarse_chans.append(chan_num)\n",
    "    \n",
    "    #if there are multiple rows for one coarse channel, the coarse\n",
    "    #channel number needs to stay the same for all of those rows:\n",
    "    elif sorted_dat_info[c,10] == sorted_dat_info[(c-1),10]:\n",
    "        sorted_coarse_chans.append(chan_num)\n",
    "        \n",
    "    #if your coarse channel is different from the last one, it needs to be incremented:\n",
    "    else:\n",
    "        chan_num += 1\n",
    "        sorted_coarse_chans.append(chan_num)\n",
    "\n",
    "sorted_dat_info[:,10] = sorted_coarse_chans\n",
    "\n",
    "#write spliced .dat file header\n",
    "\n",
    "outfile_name = 'ufsd_test.dat'\n",
    "\n",
    "outfile = open(o_fname, 'w')\n",
    "outfile.write(header_lines[0][0])\n",
    "\n",
    "for header in header_lines:\n",
    "    outfile.write(header[1])\n",
    "\n",
    "outfile.write(header_lines[0][2]+header_lines[0][3]+header_lines[0][4]+header_lines[0][5]+header_lines[0][6]+header_lines[0][7]+header_lines[0][8])\n",
    "\n",
    "#write rows for spliced .dat file\n",
    "\n",
    "for r in range(num_rows):\n",
    "#    outfile.write('{:<{width}}{: }\\trow\\n'.format(total_hit_nums[r], sorted_dat_info[r,1], width=space_padding))\n",
    "    \n",
    "    info_str = '%03d\\t'%(int(sorted_dat_info[r,0]))  #Top Hit number\n",
    "    info_str += '%10.6f\\t'%(float(sorted_dat_info[r,1]))  #Drift Rate\n",
    "    info_str += '%10.6f\\t'%(float(sorted_dat_info[r,2]))  #SNR\n",
    "    info_str += '%14.6f\\t'%(float(sorted_dat_info[r,3])) #Uncorrected Frequency:\n",
    "    info_str += '%14.6f\\t'%(float(sorted_dat_info[r,4])) #Corrected Frequency:\n",
    "    info_str += '%d\\t'%(int(sorted_dat_info[r,5])) #Index:\n",
    "    info_str += '%14.6f\\t'%(float(sorted_dat_info[r,6])) #freq_start:\n",
    "    info_str += '%14.6f\\t'%(float(sorted_dat_info[r,7])) #freq_end:\n",
    "    info_str += '%s\\t'%(float(sorted_dat_info[r,8])) #SEFD:\n",
    "    info_str += '%14.6f\\t'%(float(sorted_dat_info[r,9])) #SEFD_mid_freq:\n",
    "    info_str += '%i\\t'%(int(sorted_dat_info[r,10]))\n",
    "    info_str += '%i\\t'%(int(sorted_dat_info[r,11])) #\n",
    "    info_str +='\\n'\n",
    "    \n",
    "    outfile.write(info_str)\n",
    "    \n",
    "outfile.close()\n",
    "\n",
    "#get columns from SFD for comparison: (this part can be uncommented if you want to compare\n",
    "#the columns of our UFSD with the columns of an equivalent SFD)\n",
    "sfd_fname = '/datax/scratch/ewhite/voyager-xband/spliced_guppi_59046_80036_DIAG_VOYAGER-1_0011.rawspec.0000.dat'\n",
    "sfd_infile = open(sfd_fname, 'r')\n",
    "\n",
    "s_dat_info = []\n",
    "\n",
    "for s_line in sfd_infile.readlines():\n",
    "    if s_line[0] != '#':\n",
    "        s_items = s_line.split()\n",
    "\n",
    "        for num in range(len(s_items)):\n",
    "            s_items[num] = s_items[num].strip()\n",
    "        \n",
    "        s_dat_info.append(s_items)\n",
    "        \n",
    "s_dat_info = np.array(s_dat_info, float)\n",
    "s_sorted_dat_info = s_dat_info[s_dat_info[:,freq_index].argsort()[::-1]]\n",
    "s_sorted_dat_info[:,0] = total_hit_nums\n",
    "print(np.array_equal(s_sorted_dat_info[:,2], sorted_dat_info[:,2]))\n",
    "\n",
    "plt.hist(np.log10(sorted_dat_info[:,2]), bins=500)\n",
    "plt.xlabel('Drift Rate')\n",
    "plt.ylabel('Counts')\n",
    "plt.savefig('ufsd_drift_rates_hist.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(np.log10(s_sorted_dat_info[:,2]), bins=500)\n",
    "plt.xlabel('Drift Rate')\n",
    "plt.ylabel('Counts')\n",
    "plt.savefig('sfd_drift_rates_hist.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "outfile_drift_rates = open('SFD-vs-UFSD.txt', 'w')\n",
    "outfile_drift_rates.write('UFSD Drift Rates (D1)\\tSFD Drift Rates(D2)\\t(D2-D1)\\n')\n",
    "\n",
    "for d in range(num_rows):\n",
    "    outfile_drift_rates.write('{0}\\t\\t{1}\\t\\t{2}\\n'.format(sorted_dat_info[d,2], s_sorted_dat_info[d,2], np.subtract(s_sorted_dat_info[d,2], sorted_dat_info[d,2])))\n",
    "\n",
    "outfile_drift_rates.close()\n",
    "#print(sorted_dat_info[:,2])\n",
    "#print()\n",
    "#print(s_sorted_dat_info[:,2])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge_dats_logs: dir=/home/ewhite/voyager_dats, type=dat, cleanup=n\n",
      "merge_dats_logs: Working on filename-stem blc00_guppi_59046_80036_DIAG_VOYAGER-1_0011.rawspec.0000.dat type dat\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from turbo_seti.find_doppler.merge_dats_logs import merge_dats_logs\n",
    "\n",
    "merge_dats_logs('blc00_guppi_59046_80036_DIAG_VOYAGER-1_0011.rawspec.0000.dat', '/home/ewhite/voyager_dats', 'dat')\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
